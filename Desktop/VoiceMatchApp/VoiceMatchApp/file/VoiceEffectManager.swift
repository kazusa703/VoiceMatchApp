import Foundation
import AVFoundation
import Combine

// MARK: - ã‚¨ãƒ•ã‚§ã‚¯ãƒˆå®šç¾©
struct VoiceEffectDefinition: Identifiable {
    var id: String { key }
    let key: String
    let displayName: String
    let icon: String
    let isProOnly: Bool
    
    // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
    let defaultPitch: Float      // -2400 ~ 2400 (cents)
    let defaultRate: Float       // 0.5 ~ 2.0
    let defaultReverb: Float     // 0 ~ 100
    let defaultDistortion: Float // 0 ~ 100
}

struct VoiceEffectConstants {
    // ç„¡æ–™ãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ã‚¨ãƒ•ã‚§ã‚¯ãƒˆï¼ˆ4ç¨®é¡ï¼‰
    static let freeEffects: [VoiceEffectDefinition] = [
        VoiceEffectDefinition(
            key: "normal",
            displayName: "ãƒãƒ¼ãƒãƒ«",
            icon: "waveform",
            isProOnly: false,
            defaultPitch: 0,
            defaultRate: 1.0,
            defaultReverb: 0,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "high",
            displayName: "é«˜ã„å£°",
            icon: "arrow.up",
            isProOnly: false,
            defaultPitch: 800,
            defaultRate: 1.0,
            defaultReverb: 0,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "low",
            displayName: "ä½ã„å£°",
            icon: "arrow.down",
            isProOnly: false,
            defaultPitch: -800,
            defaultRate: 1.0,
            defaultReverb: 0,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "echo",
            displayName: "ã‚¨ã‚³ãƒ¼",
            icon: "dot.radiowaves.left.and.right",
            isProOnly: false,
            defaultPitch: 0,
            defaultRate: 1.0,
            defaultReverb: 50,
            defaultDistortion: 0
        )
    ]
    
    // Proãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ã‚¨ãƒ•ã‚§ã‚¯ãƒˆï¼ˆ+6ç¨®é¡ = åˆè¨ˆ10ç¨®é¡ï¼‰
    static let proEffects: [VoiceEffectDefinition] = [
        VoiceEffectDefinition(
            key: "robot",
            displayName: "ãƒ­ãƒœãƒƒãƒˆ",
            icon: "cpu",
            isProOnly: true,
            defaultPitch: -400,
            defaultRate: 0.9,
            defaultReverb: 30,
            defaultDistortion: 40
        ),
        VoiceEffectDefinition(
            key: "chipmunk",
            displayName: "ãƒãƒƒãƒ—ãƒãƒ³ã‚¯",
            icon: "hare",
            isProOnly: true,
            defaultPitch: 1200,
            defaultRate: 1.3,
            defaultReverb: 0,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "giant",
            displayName: "å·¨äºº",
            icon: "figure.stand",
            isProOnly: true,
            defaultPitch: -1200,
            defaultRate: 0.8,
            defaultReverb: 40,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "whisper",
            displayName: "ã•ã•ã‚„ã",
            icon: "mouth",
            isProOnly: true,
            defaultPitch: 200,
            defaultRate: 0.9,
            defaultReverb: 60,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "stadium",
            displayName: "ã‚¹ã‚¿ã‚¸ã‚¢ãƒ ",
            icon: "building.columns",
            isProOnly: true,
            defaultPitch: 0,
            defaultRate: 1.0,
            defaultReverb: 80,
            defaultDistortion: 0
        ),
        VoiceEffectDefinition(
            key: "telephone",
            displayName: "é›»è©±",
            icon: "phone",
            isProOnly: true,
            defaultPitch: 300,
            defaultRate: 1.0,
            defaultReverb: 10,
            defaultDistortion: 30
        )
    ]
    
    static var allEffects: [VoiceEffectDefinition] {
        return freeEffects + proEffects
    }
    
    static func getEffectsForUser(isPro: Bool) -> [VoiceEffectDefinition] {
        if isPro {
            return allEffects
        } else {
            return freeEffects
        }
    }
    
    static func getEffect(by key: String) -> VoiceEffectDefinition? {
        return allEffects.first { $0.key == key }
    }
}

// MARK: - ã‚¨ãƒ•ã‚§ã‚¯ãƒˆè¨­å®šï¼ˆProãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ã‚«ã‚¹ã‚¿ãƒ èª¿æ•´ï¼‰
struct VoiceEffectSettings: Codable {
    var effectKey: String
    var pitch: Float      // -2400 ~ 2400
    var rate: Float       // 0.5 ~ 2.0
    var reverb: Float     // 0 ~ 100
    var distortion: Float // 0 ~ 100
    
    init(from definition: VoiceEffectDefinition) {
        self.effectKey = definition.key
        self.pitch = definition.defaultPitch
        self.rate = definition.defaultRate
        self.reverb = definition.defaultReverb
        self.distortion = definition.defaultDistortion
    }
    
    init(effectKey: String, pitch: Float, rate: Float, reverb: Float, distortion: Float) {
        self.effectKey = effectKey
        self.pitch = pitch
        self.rate = rate
        self.reverb = reverb
        self.distortion = distortion
    }
}

// MARK: - VoiceEffectManager
class VoiceEffectManager: ObservableObject {
    static let shared = VoiceEffectManager()
    
    @Published var currentSettings: VoiceEffectSettings
    @Published var isProcessing = false
    
    init() {
        // ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒãƒ¼ãƒãƒ«
        let normalEffect = VoiceEffectConstants.freeEffects[0]
        self.currentSettings = VoiceEffectSettings(from: normalEffect)
    }
    
    // ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é¸æŠï¼ˆãƒ—ãƒªã‚»ãƒƒãƒˆé©ç”¨ï¼‰
    func selectEffect(_ definition: VoiceEffectDefinition) {
        currentSettings = VoiceEffectSettings(from: definition)
    }
    
    // ã‚«ã‚¹ã‚¿ãƒ èª¿æ•´ï¼ˆProãƒ¦ãƒ¼ã‚¶ãƒ¼ç”¨ï¼‰
    func updatePitch(_ value: Float) {
        currentSettings.pitch = value
    }
    
    func updateRate(_ value: Float) {
        currentSettings.rate = value
    }
    
    func updateReverb(_ value: Float) {
        currentSettings.reverb = value
    }
    
    func updateDistortion(_ value: Float) {
        currentSettings.distortion = value
    }
    
    // ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã‚’é©ç”¨ã—ã¦æ–°ã—ã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
    func applyEffect(to inputURL: URL, completion: @escaping (Result<URL, Error>) -> Void) {
        print("ğŸµ [VoiceEffectManager] applyEffecté–‹å§‹")
        print("ğŸµ [VoiceEffectManager] å…¥åŠ›URL: \(inputURL.path)")
        print("ğŸµ [VoiceEffectManager] ç¾åœ¨ã®ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ: \(currentSettings.effectKey)")
        print("ğŸµ [VoiceEffectManager] pitch=\(currentSettings.pitch), rate=\(currentSettings.rate), reverb=\(currentSettings.reverb)")
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        let fileExists = FileManager.default.fileExists(atPath: inputURL.path)
        print("ğŸµ [VoiceEffectManager] ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: \(fileExists)")
        
        if !fileExists {
            print("âŒ [VoiceEffectManager] å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: \(inputURL.path)")
            completion(.failure(VoiceEffectError.fileNotFound))
            return
        }
        
        // ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
        if let attributes = try? FileManager.default.attributesOfItem(atPath: inputURL.path),
           let fileSize = attributes[.size] as? Int64 {
            print("ğŸµ [VoiceEffectManager] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(fileSize) bytes")
            if fileSize == 0 {
                print("âŒ [VoiceEffectManager] ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ0ã§ã™")
                completion(.failure(VoiceEffectError.emptyFile))
                return
            }
        }
        
        // ãƒãƒ¼ãƒãƒ«ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        if currentSettings.effectKey == "normal" &&
           currentSettings.pitch == 0 &&
           currentSettings.rate == 1.0 &&
           currentSettings.reverb == 0 &&
           currentSettings.distortion == 0 {
            print("ğŸµ [VoiceEffectManager] ãƒãƒ¼ãƒãƒ«ã‚¨ãƒ•ã‚§ã‚¯ãƒˆ - å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾è¿”ã™")
            completion(.success(inputURL))
            return
        }
        
        isProcessing = true
        
        // éåŒæœŸã§ãƒˆãƒ©ãƒƒã‚¯ã‚’èª­ã¿è¾¼ã‚“ã§ã‹ã‚‰å‡¦ç†
        let asset = AVURLAsset(url: inputURL)
        print("ğŸµ [VoiceEffectManager] AVURLAssetä½œæˆå®Œäº†")
        
        // iOS 15+ ã§ã¯ loadTracks ã‚’ä½¿ç”¨
        if #available(iOS 15.0, *) {
            Task {
                do {
                    let tracks = try await asset.loadTracks(withMediaType: .audio)
                    print("ğŸµ [VoiceEffectManager] éåŒæœŸãƒˆãƒ©ãƒƒã‚¯èª­ã¿è¾¼ã¿å®Œäº†: \(tracks.count)ãƒˆãƒ©ãƒƒã‚¯")
                    
                    guard let audioTrack = tracks.first else {
                        print("âŒ [VoiceEffectManager] ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        await MainActor.run {
                            self.isProcessing = false
                            completion(.failure(VoiceEffectError.noAudioTrack))
                        }
                        return
                    }
                    
                    // duration ã‚‚éåŒæœŸã§å–å¾—
                    let duration = try await asset.load(.duration)
                    print("ğŸµ [VoiceEffectManager] duration: \(CMTimeGetSeconds(duration))ç§’")
                    
                    let outputURL = try await self.processAudioAsync(
                        asset: asset,
                        audioTrack: audioTrack,
                        duration: duration
                    )
                    
                    await MainActor.run {
                        self.isProcessing = false
                        print("âœ… [VoiceEffectManager] ã‚¨ãƒ•ã‚§ã‚¯ãƒˆå‡¦ç†å®Œäº†: \(outputURL.path)")
                        completion(.success(outputURL))
                    }
                } catch {
                    print("âŒ [VoiceEffectManager] ã‚¨ãƒ•ã‚§ã‚¯ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼: \(error)")
                    print("âŒ [VoiceEffectManager] ã‚¨ãƒ©ãƒ¼è©³ç´°: \(error.localizedDescription)")
                    await MainActor.run {
                        self.isProcessing = false
                        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãã®ã¾ã¾è¿”ã™
                        completion(.success(inputURL))
                    }
                }
            }
        } else {
            // iOS 14ä»¥ä¸‹ã®å ´åˆã¯åŒæœŸçš„ã«èª­ã¿è¾¼ã¿ï¼ˆloadValuesAsynchronouslyä½¿ç”¨ï¼‰
            asset.loadValuesAsynchronously(forKeys: ["tracks", "duration"]) { [weak self] in
                guard let self = self else { return }
                
                var tracksError: NSError?
                var durationError: NSError?
                
                let tracksStatus = asset.statusOfValue(forKey: "tracks", error: &tracksError)
                let durationStatus = asset.statusOfValue(forKey: "duration", error: &durationError)
                
                print("ğŸµ [VoiceEffectManager] tracks status: \(tracksStatus.rawValue)")
                print("ğŸµ [VoiceEffectManager] duration status: \(durationStatus.rawValue)")
                
                if let error = tracksError {
                    print("âŒ [VoiceEffectManager] tracksèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: \(error)")
                }
                if let error = durationError {
                    print("âŒ [VoiceEffectManager] durationèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: \(error)")
                }
                
                guard tracksStatus == .loaded, durationStatus == .loaded else {
                    print("âŒ [VoiceEffectManager] ã‚¢ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å¤±æ•—")
                    DispatchQueue.main.async {
                        self.isProcessing = false
                        completion(.success(inputURL))
                    }
                    return
                }
                
                let tracks = asset.tracks(withMediaType: .audio)
                print("ğŸµ [VoiceEffectManager] ãƒˆãƒ©ãƒƒã‚¯æ•°: \(tracks.count)")
                
                guard let audioTrack = tracks.first else {
                    print("âŒ [VoiceEffectManager] ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒˆãƒ©ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    DispatchQueue.main.async {
                        self.isProcessing = false
                        completion(.success(inputURL))
                    }
                    return
                }
                
                do {
                    let outputURL = try self.processAudioWithAVFoundationSync(
                        asset: asset,
                        audioTrack: audioTrack
                    )
                    DispatchQueue.main.async {
                        self.isProcessing = false
                        print("âœ… [VoiceEffectManager] ã‚¨ãƒ•ã‚§ã‚¯ãƒˆå‡¦ç†å®Œäº†: \(outputURL.path)")
                        completion(.success(outputURL))
                    }
                } catch {
                    print("âŒ [VoiceEffectManager] å‡¦ç†ã‚¨ãƒ©ãƒ¼: \(error)")
                    DispatchQueue.main.async {
                        self.isProcessing = false
                        completion(.success(inputURL))
                    }
                }
            }
        }
    }
    
    // iOS 15+ ç”¨ã®éåŒæœŸå‡¦ç†
    @available(iOS 15.0, *)
    private func processAudioAsync(asset: AVURLAsset, audioTrack: AVAssetTrack, duration: CMTime) async throws -> URL {
        print("ğŸµ [processAudioAsync] å‡¦ç†é–‹å§‹")
        
        // å‡ºåŠ›URL
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("m4a")
        
        print("ğŸµ [processAudioAsync] å‡ºåŠ›URL: \(outputURL.path)")
        
        // AVMutableComposition ã‚’ä½¿ç”¨
        let composition = AVMutableComposition()
        guard let compositionAudioTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            print("âŒ [processAudioAsync] compositionTrackä½œæˆå¤±æ•—")
            throw VoiceEffectError.compositionFailed
        }
        
        let timeRange = CMTimeRange(start: .zero, duration: duration)
        print("ğŸµ [processAudioAsync] timeRange: start=0, duration=\(CMTimeGetSeconds(duration))")
        
        try compositionAudioTrack.insertTimeRange(timeRange, of: audioTrack, at: .zero)
        print("ğŸµ [processAudioAsync] insertTimeRangeå®Œäº†")
        
        // ã‚¿ã‚¤ãƒ ã‚¹ã‚±ãƒ¼ãƒ«ã§ãƒ”ãƒƒãƒã¨é€Ÿåº¦ã‚’èª¿æ•´
        if currentSettings.rate != 1.0 {
            let scaledDuration = CMTimeMultiplyByFloat64(duration, multiplier: Float64(1.0 / currentSettings.rate))
            compositionAudioTrack.scaleTimeRange(timeRange, toDuration: scaledDuration)
            print("ğŸµ [processAudioAsync] rateèª¿æ•´å®Œäº†: \(currentSettings.rate)")
        }
        
        // ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetAppleM4A) else {
            print("âŒ [processAudioAsync] exportSessionä½œæˆå¤±æ•—")
            throw VoiceEffectError.exportFailed
        }
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .m4a
        
        print("ğŸµ [processAudioAsync] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆé–‹å§‹")
        
        await exportSession.export()
        
        print("ğŸµ [processAudioAsync] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: \(exportSession.status.rawValue)")
        
        if exportSession.status == .failed {
            print("âŒ [processAudioAsync] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: \(exportSession.error?.localizedDescription ?? "ä¸æ˜")")
            throw exportSession.error ?? VoiceEffectError.exportFailed
        }
        
        // å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        let outputExists = FileManager.default.fileExists(atPath: outputURL.path)
        print("ğŸµ [processAudioAsync] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨: \(outputExists)")
        
        if let attrs = try? FileManager.default.attributesOfItem(atPath: outputURL.path),
           let size = attrs[.size] as? Int64 {
            print("ğŸµ [processAudioAsync] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: \(size) bytes")
        }
        
        return outputURL
    }
    
    // iOS 14ä»¥ä¸‹ç”¨ã®åŒæœŸå‡¦ç†
    private func processAudioWithAVFoundationSync(asset: AVURLAsset, audioTrack: AVAssetTrack) throws -> URL {
        print("ğŸµ [processAudioSync] å‡¦ç†é–‹å§‹")
        
        // å‡ºåŠ›URL
        let outputURL = FileManager.default.temporaryDirectory
            .appendingPathComponent(UUID().uuidString)
            .appendingPathExtension("m4a")
        
        // AVMutableComposition ã‚’ä½¿ç”¨
        let composition = AVMutableComposition()
        guard let compositionAudioTrack = composition.addMutableTrack(
            withMediaType: .audio,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            throw VoiceEffectError.compositionFailed
        }
        
        let timeRange = CMTimeRange(start: .zero, duration: asset.duration)
        try compositionAudioTrack.insertTimeRange(timeRange, of: audioTrack, at: .zero)
        
        // ã‚¿ã‚¤ãƒ ã‚¹ã‚±ãƒ¼ãƒ«ã§ãƒ”ãƒƒãƒã¨é€Ÿåº¦ã‚’èª¿æ•´
        if currentSettings.rate != 1.0 {
            let scaledDuration = CMTimeMultiplyByFloat64(asset.duration, multiplier: Float64(1.0 / currentSettings.rate))
            compositionAudioTrack.scaleTimeRange(timeRange, toDuration: scaledDuration)
        }
        
        // ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        guard let exportSession = AVAssetExportSession(asset: composition, presetName: AVAssetExportPresetAppleM4A) else {
            throw VoiceEffectError.exportFailed
        }
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .m4a
        
        let semaphore = DispatchSemaphore(value: 0)
        var exportError: Error?
        
        exportSession.exportAsynchronously {
            if exportSession.status == .failed {
                exportError = exportSession.error
                print("âŒ [processAudioSync] ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¤±æ•—: \(exportSession.error?.localizedDescription ?? "ä¸æ˜")")
            }
            semaphore.signal()
        }
        
        semaphore.wait()
        
        if let error = exportError {
            throw error
        }
        
        return outputURL
    }
}

enum VoiceEffectError: LocalizedError {
    case bufferCreationFailed
    case renderingFailed
    case noAudioTrack
    case compositionFailed
    case exportFailed
    case fileNotFound
    case emptyFile
    
    var errorDescription: String? {
        switch self {
        case .bufferCreationFailed:
            return "éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .renderingFailed:
            return "éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .noAudioTrack:
            return "éŸ³å£°ãƒˆãƒ©ãƒƒã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        case .compositionFailed:
            return "éŸ³å£°åˆæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .exportFailed:
            return "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .fileNotFound:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
        case .emptyFile:
            return "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™"
        }
    }
}
